{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOPB8M/lEG2X/EnR1ZCpWg5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SridharSola/Knowledge-Distillation-FER/blob/main/FERPlusClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZrpcRjj5fwZ"
      },
      "outputs": [],
      "source": [
        "class KDFplusDataSet(data.Dataset):\n",
        "    def __init__(self, f1, f2,  partition = 'train',  transform = None, num_classes = 8):\n",
        "        \n",
        "        self.transform = transform\n",
        "        self.root = f1\n",
        "        self.mask_file = f2\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.partition = partition\n",
        "        if partition == 'train':\n",
        "          self.rand = 0.5\n",
        "        else:\n",
        "          self.rand = 0\n",
        "        self.transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                        transforms.Resize((224, 224)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                            std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "        if partition == 'train':\n",
        "            self.transform1 = A.Compose([\n",
        "                                      A.HorizontalFlip(), A.HueSaturationValue(), A.RandomContrast(), \n",
        "                                      A.ShiftScaleRotate(shift_limit = 0.0625,scale_limit = 0.1 ,rotate_limit = 3, p = 0.5),\n",
        "                                      A.IAAAffine(scale = (1.0, 1.25), rotate = 0.0, p = 0.5)\n",
        "                                      ],\n",
        "                                        additional_targets={'image1':'image'})\n",
        "            self.transform2 = transforms.Compose([\n",
        "                                                  transforms.ToPILImage(),\n",
        "                                                  transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "                                                  ])\n",
        "\n",
        "\n",
        "        NAME_COLUMN = 0\n",
        "        LABEL_COLUMN = 1\n",
        "        df_train = pd.read_csv('/content/drive/MyDrive/FERPLUS/ferplus_trainvalid_list.txt', sep=' ', header=None)\n",
        "        df_test = pd.read_csv('/content/drive/MyDrive/FERPLUS/ferplus_test.txt', sep=' ', header=None)\n",
        "        \n",
        "        if partition == 'train':           \n",
        "            self.label = df_train.iloc[:, LABEL_COLUMN].values           \n",
        "            file_names = df_train.iloc[:, NAME_COLUMN].values    \n",
        "        else: \n",
        "            self.label = df_test.iloc[:, LABEL_COLUMN].values             \n",
        "            file_names = df_test.iloc[:, NAME_COLUMN].values\n",
        "            \n",
        "        self.new_label = [] \n",
        "\n",
        "        for label in self.label:\n",
        "            self.new_label.append(self.change_emotion_label_same_as_affectnet(label))\n",
        "            \n",
        "        self.label = self.new_label\n",
        "        \n",
        "        #self.file_paths = []\n",
        "        self.unmasked_file_paths = []\n",
        "        self.masked_file_paths = []\n",
        "        self.dataset = []\n",
        "        # use raf aligned images for training/testing\n",
        "        for f in file_names:\n",
        "          f = f + '.png'\n",
        "          if partition == 'train':\n",
        "            working_dir = os.path.join(self.root, 'FER2013TrainValid')\n",
        "          else:\n",
        "            working_dir = os.path.join(self.root, 'FER2013Test')\n",
        "          \n",
        "          #Putting non-masked image paths into unmasked_file_paths\n",
        "          upath = os.path.join(working_dir, f)\n",
        "          self.unmasked_file_paths.append(upath)\n",
        "          #Putting masked image paths into masked_file_paths\n",
        "          if partition == 'train':\n",
        "            working_dir = os.path.join(self.mask_file, 'withmask_FER2013TrainValid')\n",
        "          else:\n",
        "            working_dir = os.path.join(self.mask_file, 'withmask_FER2013Test')\n",
        "          \n",
        "          mpath = os.path.join(working_dir, f)\n",
        "          self.masked_file_paths.append(mpath)\n",
        "          item = (upath, mpath)\n",
        "          self.dataset.append(item)\n",
        "                \n",
        "        \n",
        "\n",
        "\n",
        " \n",
        "    def change_emotion_label_same_as_affectnet(self, emo_to_return):\n",
        "        \"\"\"\n",
        "        Parse labels to make them compatible with AffectNet.  \n",
        "        #https://github.com/siqueira-hc/Efficient-Facial-Feature-Learning-with-Wide-Ensemble-based-Convolutional-Neural-Networks/blob/master/model/utils/udata.py\n",
        "        \"\"\"    \n",
        "        if emo_to_return == 2:\n",
        "            emo_to_return = 3\n",
        "        elif emo_to_return == 3:\n",
        "            emo_to_return = 2\n",
        "        elif emo_to_return == 4:\n",
        "            emo_to_return = 6\n",
        "        elif emo_to_return == 6:\n",
        "            emo_to_return = 4\n",
        "\n",
        "        return emo_to_return \n",
        "           \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "      \"\"\"\n",
        "      Here we read the actual images\n",
        "      We randomly apply few transforms to the image for image augmentation\n",
        "      Return: image1, image 2 and their label\n",
        "      \"\"\"\n",
        "      \"\"\"\n",
        "      u_imgPath = self.unmasked_file_paths[index]\n",
        "      uimg = cv2.imread(u_imgPath)\n",
        "      uimg = cv2.cvtColor(uimg, cv2.COLOR_BGR2RGB)\n",
        "  \n",
        "      m_imgPath = self.masked_file_paths[index]\n",
        "      mimg = cv2.imread(m_imgPath)\n",
        "      mimg = cv2.cvtColor(mimg, cv2.COLOR_BGR2RGB)\n",
        "      \"\"\"\n",
        "      uimg_path, mimg_path = self.dataset[index]\n",
        "      uimg = cv2.imread(uimg_path)\n",
        "      uimg = cv2.cvtColor(uimg, cv2.COLOR_BGR2RGB)\n",
        "      mimg = cv2.imread(mimg_path)\n",
        "      mimg = cv2.cvtColor(mimg, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "      \"\"\"\n",
        "      Note on cv2.imread(): OpenCV uses the BGR format\n",
        "      We need to change to RGB format(ideally before returning the image)\n",
        "      \"\"\"\n",
        "      if self.partition == 'train':\n",
        "        transformed = self.transform1(image = uimg, image1 = mimg)\n",
        "        uimg  = transformed['image']\n",
        "        mimg = transformed['image1']\n",
        "        uimg = self.transform2(uimg)\n",
        "        mimg = self.transform2(mimg)\n",
        "      else:\n",
        "        uimg = self.transform(uimg)\n",
        "        mimg = self.transform(mimg)\n",
        "      label = self.label[index]\n",
        "      r = random.uniform(0, 1)\n",
        "      if r <self.rand:\n",
        "        return uimg, uimg, label#, uimg_path, mimg_path\n",
        "      else:\n",
        "        return uimg, mimg, label#, uimg_path, mimg_path\n",
        "\n",
        "\n",
        "    def change_rand(self, new_rand):\n",
        "      self.rand = new_rand\n",
        "    def __len__(self):\n",
        "      return len(self.dataset)\n",
        "    \n",
        "    def show_img(self, index):\n",
        "      uimg, mimg, label= self.__getitem__(index)\n",
        "      uimg = uimg.permute(1, 2, 0)\n",
        "      mimg = mimg.permute(1, 2, 0)\n",
        "\n",
        "      f = plt.figure()\n",
        "      f.add_subplot(1,2, 1)\n",
        "      plt.imshow(np.rot90(uimg,0))\n",
        "      f.add_subplot(1,2, 2)\n",
        "      plt.imshow(np.rot90(mimg,0))\n",
        "      plt.show(block=True)\n",
        "      #print(uimg_path)\n",
        "      print(\"Label: \", label) "
      ]
    }
  ]
}